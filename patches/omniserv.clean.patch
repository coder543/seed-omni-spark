diff --git a/decoder/audio/codec/config.properties b/decoder/audio/codec/config.properties
index 8a071a3..058b9a8 100644
--- a/decoder/audio/codec/config.properties
+++ b/decoder/audio/codec/config.properties
@@ -4,4 +4,5 @@ metrics_address=http://0.0.0.0:8083
 disable_token_authorization=true
 default_startup_timeout=600
 default_response_timeout=300
-
+max_response_size=104857600
+max_request_size=104857600
diff --git a/decoder/audio/codec/requirements.txt b/decoder/audio/codec/requirements.txt
index 85f9d87..053b819 100644
--- a/decoder/audio/codec/requirements.txt
+++ b/decoder/audio/codec/requirements.txt
@@ -9,6 +9,5 @@ pynvml==11.5.0  # for torchserve
 pyyaml==6.0.1  # for torchserve
 requests==2.32.3
 scipy<=1.13.1
-torch==2.5.1
+# Let base image provide torch/triton; install torchserve only.
 torchserve==0.12
-triton==3.1.0; sys_platform == 'linux'  # for torch and torchserve
diff --git a/docker/omni_decoder_vision.dockerfile b/docker/omni_decoder_vision.dockerfile
index 566aa2a..633cc52 100644
--- a/docker/omni_decoder_vision.dockerfile
+++ b/docker/omni_decoder_vision.dockerfile
@@ -1,4 +1,4 @@
-FROM pytorch/pytorch:2.6.0-cuda12.4-cudnn9-devel
+FROM nvcr.io/nvidia/pytorch:25.10-py3
 
 RUN apt-get update && apt-get install -y \
     git \
@@ -12,11 +12,11 @@ WORKDIR /app/track_b
 
 RUN pip install --no-cache-dir --upgrade pip
 RUN pip install --no-cache-dir ninja packaging && \
-    pip install --no-cache-dir flash-attn --no-build-isolation
+    (pip install --no-cache-dir flash-attn --no-build-isolation || true)
     
 COPY decoder/vision/track_b/ /app/track_b/
-RUN pip install -r requirements.txt && \
-    pip install --no-cache-dir uvicorn einops accelerate
+RUN pip install --no-cache-dir -r requirements.min.txt
+RUN pip install --no-cache-dir torchao==0.14.1
 
 COPY util/storage/wbl_storage_utility /wbl_storage_utility
 RUN pip install --no-cache-dir /wbl_storage_utility
diff --git a/docker/omni_encoder_vision.dockerfile b/docker/omni_encoder_vision.dockerfile
index 35e8fbc..7375fbc 100644
--- a/docker/omni_encoder_vision.dockerfile
+++ b/docker/omni_encoder_vision.dockerfile
@@ -30,8 +30,8 @@ RUN pip install --no-cache-dir /wbl_storage_utility
 # Copy requirements file
 COPY encoder/vision/track_b .
 
-# Install Python dependencies
-RUN pip install --no-cache-dir -r requirements.txt
+# Install Python dependencies (aarch64-safe)
+RUN pip install --no-cache-dir -r requirements.aarch64.txt
 
 # Expose port
 EXPOSE 8000
diff --git a/omni_chainer/omni_chainer/core/omni/_tools.py b/omni_chainer/omni_chainer/core/omni/_tools.py
index 03c676f..02b8075 100644
--- a/omni_chainer/omni_chainer/core/omni/_tools.py
+++ b/omni_chainer/omni_chainer/core/omni/_tools.py
@@ -78,7 +78,8 @@ def trace_request(func: Callable) -> Callable:
 
 
 def flatten_extra_body(request: ChatCompletionRequest) -> dict:
-  request_json = request.model_dump()
+  # Use JSON serialization to avoid pydantic SerializationIterator objects.
+  request_json = json.loads(request.model_dump_json())
   extra_body = request_json.pop("extra_body", None)
   if extra_body is not None:
     logger.debug(f"flattening extra body: {extra_body}")
