diff --git a/decoder/audio/codec/Dockerfile b/decoder/audio/codec/Dockerfile
index 764643e..b28700f 100644
--- a/decoder/audio/codec/Dockerfile
+++ b/decoder/audio/codec/Dockerfile
@@ -1,39 +1,26 @@
-FROM nvcr.io/nvidia/pytorch:22.12-py3
+FROM nvcr.io/nvidia/pytorch:25.10-py3
+
+ARG DEBIAN_FRONTEND=noninteractive
+ENV TZ=Etc/UTC
 
-ARG CONDA_ENV=audiollm
-ENV CONDA_ENV=$CONDA_ENV
 WORKDIR /app
 
 # 필수 패키지 설치 및 캐시 정리
 RUN apt-get update && \
-    apt-get install -y wget bzip2 ca-certificates libsndfile-dev openjdk-11-jdk && \
+    apt-get install -y wget bzip2 ca-certificates libsndfile-dev ffmpeg openjdk-11-jdk && \
     apt-get clean && rm -rf /var/lib/apt/lists/*
 
 # Optionally set JAVA_HOME (if TorchServe specifically needs it)
 ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
 
-# Miniconda 설치 및 초기화
-ENV CONDA_HOME=/opt/conda
-ENV PATH=/opt/conda/bin:$PATH
-RUN ARCH=$(uname -m) && \
-    wget "https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-${ARCH}.sh" -O /tmp/miniforge.sh && \
-    bash /tmp/miniforge.sh -b -p $CONDA_HOME && \
-    rm /tmp/miniforge.sh
-
-# Create your environment
-RUN conda create -y -n $CONDA_ENV python=3.11
-
-# Install packages into that environment (conda or pip)
-RUN conda run -n $CONDA_ENV conda install -y -c conda-forge ffmpeg libsndfile==1.2.2
-
 COPY requirements.txt /app/requirements.txt
-RUN conda run -n $CONDA_ENV pip install --no-cache-dir -r /app/requirements.txt \
+RUN python -m pip install --no-cache-dir -r /app/requirements.txt \
     --extra-index-url https://download.pytorch.org/whl/cu118
 
 COPY src /app/src
 COPY entrypoint.sh /app/entrypoint.sh
 COPY setup.py /app/setup.py
-RUN conda run -n $CONDA_ENV pip install -e /app
+RUN python -m pip install -e /app
 
 RUN chmod +x /app/entrypoint.sh
 ENTRYPOINT ["/app/entrypoint.sh"]
diff --git a/decoder/audio/codec/config.properties b/decoder/audio/codec/config.properties
index 8a071a3..058b9a8 100644
--- a/decoder/audio/codec/config.properties
+++ b/decoder/audio/codec/config.properties
@@ -4,4 +4,5 @@ metrics_address=http://0.0.0.0:8083
 disable_token_authorization=true
 default_startup_timeout=600
 default_response_timeout=300
-
+max_response_size=104857600
+max_request_size=104857600
diff --git a/decoder/audio/codec/entrypoint.sh b/decoder/audio/codec/entrypoint.sh
index 610741a..d13e12e 100644
--- a/decoder/audio/codec/entrypoint.sh
+++ b/decoder/audio/codec/entrypoint.sh
@@ -1,5 +1,3 @@
 #!/bin/bash
 
-source $CONDA_HOME/etc/profile.d/conda.sh
-conda activate $CONDA_ENV
-exec torchserve $@
\ No newline at end of file
+exec torchserve $@
diff --git a/decoder/audio/codec/requirements.txt b/decoder/audio/codec/requirements.txt
index 85f9d87..053b819 100644
--- a/decoder/audio/codec/requirements.txt
+++ b/decoder/audio/codec/requirements.txt
@@ -9,6 +9,5 @@ pynvml==11.5.0  # for torchserve
 pyyaml==6.0.1  # for torchserve
 requests==2.32.3
 scipy<=1.13.1
-torch==2.5.1
+# Let base image provide torch/triton; install torchserve only.
 torchserve==0.12
-triton==3.1.0; sys_platform == 'linux'  # for torch and torchserve
diff --git a/decoder/audio/codec/src/audiollm/decoder/unit_bigvgan/handler_concrete.py b/decoder/audio/codec/src/audiollm/decoder/unit_bigvgan/handler_concrete.py
index 46d290c..46356f5 100644
--- a/decoder/audio/codec/src/audiollm/decoder/unit_bigvgan/handler_concrete.py
+++ b/decoder/audio/codec/src/audiollm/decoder/unit_bigvgan/handler_concrete.py
@@ -117,7 +117,13 @@ class ConcreteUnitBigVGANHandler(base_handler.BaseHandler):
         """
         super().initialize(context)
 
+        if torch.cuda.is_available():
+            self.device = torch.device("cuda")
+        else:
+            self.device = torch.device("cpu")
+
         self._dtype = utils.to_dtype(os.getenv("AUDIOLLM_DTYPE", "float32"))
+        self.model.to(self.device)
         self.model.to(self._dtype)
 
         self.model.compile()
diff --git a/decoder/audio/codec/src/audiollm/decoder/unit_bigvgan/handler_concrete_zeroshot.py b/decoder/audio/codec/src/audiollm/decoder/unit_bigvgan/handler_concrete_zeroshot.py
index c67b39e..b323185 100644
--- a/decoder/audio/codec/src/audiollm/decoder/unit_bigvgan/handler_concrete_zeroshot.py
+++ b/decoder/audio/codec/src/audiollm/decoder/unit_bigvgan/handler_concrete_zeroshot.py
@@ -141,7 +141,13 @@ class ConcreteZSUnitBigVGANHandler(base_handler.BaseHandler):
         """
         super().initialize(context)
 
+        if torch.cuda.is_available():
+            self.device = torch.device("cuda")
+        else:
+            self.device = torch.device("cpu")
+
         self._dtype = utils.to_dtype(os.getenv("AUDIOLLM_DTYPE", "float32"))
+        self.model.to(self.device)
         self.model.to(self._dtype)
 
         self.model.compile()
diff --git a/decoder/audio/track_b/app/configs.py b/decoder/audio/track_b/app/configs.py
index 4f8fed7..65a87e4 100644
--- a/decoder/audio/track_b/app/configs.py
+++ b/decoder/audio/track_b/app/configs.py
@@ -15,6 +15,9 @@ class Settings(pydantic_settings.BaseSettings):
     finetuned_model: str = "NCCosybigvganDecoder"
     default_speaker: str = "fkms"
     speaker_config_path: Optional[str] = None
+    audio_sample_rate: int = pydantic.Field(
+        default=24000, validation_alias="AUDIO_DECODER_SAMPLE_RATE"
+    )
 
     s3_endpoint: str = pydantic.Field(default="", validation_alias="NCP_S3_ENDPOINT")
     s3_region: str = pydantic.Field(default="kr-standard", validation_alias="NCP_S3_REGION")
diff --git a/decoder/audio/track_b/app/decoders.py b/decoder/audio/track_b/app/decoders.py
index 32a62ae..988eef1 100644
--- a/decoder/audio/track_b/app/decoders.py
+++ b/decoder/audio/track_b/app/decoders.py
@@ -17,10 +17,14 @@ from . import exceptions, references, server_types
 
 
 async def request(
-    endpoint: str, model_name: str, units: List[int], speaker: references.Reference
+    endpoint: str,
+    model_name: str,
+    units: List[int],
+    speaker: references.Reference,
+    format: str = "wav",
 ) -> bytes:
-    """Decode audio units into wav bytes."""
-    data = {"unit": units, "format": "wav"}
+    """Decode audio units into audio bytes."""
+    data = {"unit": units, "format": format}
     if isinstance(speaker, references.FinetunedReference):
         data["speaker"] = speaker.speaker_id
     else:
@@ -45,11 +49,33 @@ def _get_pcm_from_wav(wav: BinaryIO) -> bytes:
         return wave_file.readframes(num_frames)
 
 
-def convert_audio(wav: bytes, format: server_types.Format) -> bytes:
-    src = io.BytesIO(wav)
+def _wrap_pcm_to_wav(pcm: bytes, sample_rate: int) -> bytes:
+    buf = io.BytesIO()
+    with wave.open(buf, "wb") as wave_file:
+        wave_file.setnchannels(1)
+        wave_file.setsampwidth(2)
+        wave_file.setframerate(sample_rate)
+        wave_file.writeframes(pcm)
+    return buf.getvalue()
 
-    if format == "pcm":
-        return _get_pcm_from_wav(src)
+
+def convert_audio(
+    audio_bytes: bytes,
+    format: server_types.Format,
+    src_format: server_types.Format = "wav",
+    sample_rate: int = 24000,
+) -> bytes:
+    if src_format == "pcm":
+        if format == "pcm":
+            return audio_bytes
+        wav_bytes = _wrap_pcm_to_wav(audio_bytes, sample_rate)
+        if format == "wav":
+            return wav_bytes
+        src = io.BytesIO(wav_bytes)
+    else:
+        src = io.BytesIO(audio_bytes)
+        if format == "pcm":
+            return _get_pcm_from_wav(src)
 
     segment = pydub.AudioSegment.from_wav(src)
 
diff --git a/decoder/audio/track_b/app/main.py b/decoder/audio/track_b/app/main.py
index c0785d2..712f0b4 100644
--- a/decoder/audio/track_b/app/main.py
+++ b/decoder/audio/track_b/app/main.py
@@ -82,11 +82,17 @@ async def completions(request: server_types.Request):
     is_zeroshot = isinstance(speaker, references.ZeroshotReference)
     model_name = settings.zeroshot_model if is_zeroshot else settings.finetuned_model
 
+    decoder_format = "wav" if is_zeroshot else "pcm"
     wav_bytes = await decoders.request(
-        settings.endpoint, model_name, request.units, speaker
+        settings.endpoint, model_name, request.units, speaker, format=decoder_format
     )
 
-    audio_bytes = decoders.convert_audio(wav_bytes, request.format)
+    audio_bytes = decoders.convert_audio(
+        wav_bytes,
+        request.format,
+        src_format=decoder_format,
+        sample_rate=settings.audio_sample_rate,
+    )
     
     # 요청 포맷 기반으로 확장자/키 생성
     # request.format 은 "mp3", "wav" 같은 문자열(서버 타입 alias)이라고 가정
diff --git a/docker/omni_decoder_vision.dockerfile b/docker/omni_decoder_vision.dockerfile
index 566aa2a..633cc52 100644
--- a/docker/omni_decoder_vision.dockerfile
+++ b/docker/omni_decoder_vision.dockerfile
@@ -1,4 +1,4 @@
-FROM pytorch/pytorch:2.6.0-cuda12.4-cudnn9-devel
+FROM nvcr.io/nvidia/pytorch:25.10-py3
 
 RUN apt-get update && apt-get install -y \
     git \
@@ -12,11 +12,11 @@ WORKDIR /app/track_b
 
 RUN pip install --no-cache-dir --upgrade pip
 RUN pip install --no-cache-dir ninja packaging && \
-    pip install --no-cache-dir flash-attn --no-build-isolation
+    (pip install --no-cache-dir flash-attn --no-build-isolation || true)
     
 COPY decoder/vision/track_b/ /app/track_b/
-RUN pip install -r requirements.txt && \
-    pip install --no-cache-dir uvicorn einops accelerate
+RUN pip install --no-cache-dir --no-deps -r requirements.min.txt
+RUN pip uninstall -y torchao || true
 
 COPY util/storage/wbl_storage_utility /wbl_storage_utility
 RUN pip install --no-cache-dir /wbl_storage_utility
diff --git a/docker/omni_encoder_vision.dockerfile b/docker/omni_encoder_vision.dockerfile
index 35e8fbc..7375fbc 100644
--- a/docker/omni_encoder_vision.dockerfile
+++ b/docker/omni_encoder_vision.dockerfile
@@ -30,8 +30,8 @@ RUN pip install --no-cache-dir /wbl_storage_utility
 # Copy requirements file
 COPY encoder/vision/track_b .
 
-# Install Python dependencies
-RUN pip install --no-cache-dir -r requirements.txt
+# Install Python dependencies (aarch64-safe)
+RUN pip install --no-cache-dir -r requirements.aarch64.txt
 
 # Expose port
 EXPOSE 8000
diff --git a/omni_chainer/omni_chainer/core/omni/_tools.py b/omni_chainer/omni_chainer/core/omni/_tools.py
index 03c676f..02b8075 100644
--- a/omni_chainer/omni_chainer/core/omni/_tools.py
+++ b/omni_chainer/omni_chainer/core/omni/_tools.py
@@ -78,7 +78,8 @@ def trace_request(func: Callable) -> Callable:
 
 
 def flatten_extra_body(request: ChatCompletionRequest) -> dict:
-  request_json = request.model_dump()
+  # Use JSON serialization to avoid pydantic SerializationIterator objects.
+  request_json = json.loads(request.model_dump_json())
   extra_body = request_json.pop("extra_body", None)
   if extra_body is not None:
     logger.debug(f"flattening extra body: {extra_body}")
